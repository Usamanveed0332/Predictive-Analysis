# -*- coding: utf-8 -*-
"""Predictive Analysis For Bank Marketing Campaign.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13S19Vl2saNGA-llrkmp7isTMOjcey09m

#Importing Libraries
"""

import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
plt.rc("font", size=14)
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import seaborn as sns
sns.set(style="white")
sns.set(style="whitegrid", color_codes=True)

"""# Importing Data"""

data = pd.read_csv('bankMarketingCampaign.csv')
print(data.shape)
X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

data.head()

"""**Grouping unnecessary categories for better modeling**"""

data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])
data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])
data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])

"""#Data Exploration"""

sns.countplot(x='y',data=data, palette='Set2')
plt.show()
plt.savefig('count_plot')

data.dtypes

"""#Mean of Data"""

data.select_dtypes(include=['int', 'float']).groupby(data['y']).mean()

data.select_dtypes(include=['int', 'float']).groupby(data['job']).mean()

data.select_dtypes(include=['int', 'float']).groupby(data['marital']).mean()

data.select_dtypes(include=['int', 'float']).groupby(data['education']).mean()

"""#Visualizations"""

pd.crosstab(data.job,data.y).plot(kind='bar')
plt.title('Purchase Frequency for Job Title')
plt.xlabel('Job')
plt.ylabel('Frequency of Purchase')
plt.savefig('purchase_fre_job')

table=pd.crosstab(data.marital,data.y)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)
plt.title('Stacked Bar Chart of Marital Status vs Purchase')
plt.xlabel('Marital Status')
plt.ylabel('Proportion of Customers')
plt.savefig('mariral_vs_pur_stack')

table=pd.crosstab(data.education,data.y)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)
plt.title('Stacked Bar Chart of Education vs Purchase')
plt.xlabel('Education')
plt.ylabel('Proportion of Customers')
plt.savefig('edu_vs_pur_stack')

pd.crosstab(data.day_of_week,data.y).plot(kind='bar')
plt.title('Purchase Frequency for Day of Week')
plt.xlabel('Day of Week')
plt.ylabel('Frequency of Purchase')
plt.savefig('pur_dayofweek_bar')

pd.crosstab(data.month,data.y).plot(kind='bar')
plt.title('Purchase Frequency for Month')
plt.xlabel('Month')
plt.ylabel('Frequency of Purchase')
plt.savefig('pur_fre_month_bar')

data.age.hist()
plt.title('Histogram of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.savefig('hist_age')

pd.crosstab(data.poutcome,data.y).plot(kind='bar')
plt.title('Purchase Frequency for Poutcome')
plt.xlabel('Poutcome')
plt.ylabel('Frequency of Purchase')
plt.savefig('pur_fre_pout_bar')

print(X)

print(X.dtype)

strings_only = [item for item in X if isinstance(item, str)]
print(X)

data.head()

"""#One Hot Encoding"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,2,3,4,5,6,7,8,9,14])], remainder='passthrough')
X = np.array(ct.fit_transform(X))

"""#Train & Test Split"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

from sklearn.linear_model import LogisticRegression
from sklearn import metrics
logreg = LogisticRegression(max_iter=50000)
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score
confusion_matrix = confusion_matrix(y_test, y_pred)
print(confusion_matrix)

accuracy_score(y_test, y_pred)
